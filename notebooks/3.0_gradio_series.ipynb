{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILDING NLP WEB APPS WITH GRADIO AND HUGGING FACE TRANSFORMERS\n",
    "\n",
    "After trying to load 2 summarization models in parallel for comparisons, let's try to load 2 models in *series* for two distinct tasks - first, to translate Chinese text into English, and then summarize the English output.\n",
    "\n",
    "The results for \"chain linking\" transformer models are frankly quite patchy, but as the quality of models improve over time, this will be an interesting area to watch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "from gradio.mix import Series\n",
    "from transformers import pipeline, MarianMTModel, MarianTokenizer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. DEFINE TEXT CLEANING, TRANSLATION AND SUMMARIZATION FUNCTIONS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweak the text cleaning function further if you wish\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"\\n\", \" \", text)\n",
    "    text = re.sub(r\"\\n\\n\", \" \", text)\n",
    "    text = re.sub(r\"\\t\", \" \", text)\n",
    "    text = text.strip(\" \")\n",
    "    text = re.sub(\n",
    "        \" +\", \" \", text\n",
    "    ).strip()  # get rid of multiple spaces and replace with a single\n",
    "    return text  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 SUMMARIZATION VIA HUGGING FACE PIPELINE\n",
    "\n",
    "I'm re-using the code from notebook2.0. Feel free to use a different summarization model if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_summ = pipeline(\n",
    "    \"summarization\",\n",
    "    model=\"facebook/bart-large-cnn\",  # switch out to \"t5-small\" etc if you wish\n",
    "    tokenizer=\"facebook/bart-large-cnn\",  # as above\n",
    "    framework=\"pt\",\n",
    ")\n",
    "\n",
    "# First of 2 functions in Gradio series\n",
    "def fb_summarizer(text):\n",
    "    input_text = clean_text(text)\n",
    "    results = pipeline_summ(input_text)\n",
    "    return results[0][\"summary_text\"]\n",
    "\n",
    "\n",
    "# First of 2 Gradio apps that we'll put in \"series\"\n",
    "summary = gr.Interface(\n",
    "    fn=fb_summarizer, inputs=gr.inputs.Textbox(), outputs=gr.outputs.Textbox()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 TRANSLATION VIA MARIANMT\n",
    "\n",
    "There are also a few options for translation models on Hugging Face's model hub. I've tried out the MarianMT models in [previous repos](https://github.com/chuachinhon/practical_nlp), and will stick to that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = (\n",
    "    \"Helsinki-NLP/opus-mt-zh-en\"\n",
    ")  # switch out the Marian MT model as required for your use case\n",
    "\n",
    "# Second of 2 summarization function\n",
    "def cn_to_eng(text):\n",
    "    input_text = clean_text(text)\n",
    "\n",
    "    model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    batch = tokenizer.prepare_seq2seq_batch(input_text, return_tensors=\"pt\")\n",
    "\n",
    "    output = model.generate(**batch)\n",
    "\n",
    "    translated = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "\n",
    "    return translated[0]\n",
    "\n",
    "\n",
    "# Second of 2 Gradio apps that we'll put in \"parallel\"\n",
    "translation = gr.Interface(\n",
    "    fn=cn_to_eng, inputs=gr.inputs.Textbox(), outputs=gr.outputs.Textbox()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. LAUNCH GRADIO\n",
    "\n",
    "Note the sequence of the 2 functions, and line them up as you intend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally at: http://127.0.0.1:7861/\n",
      "To create a public link, set `share=True` in `launch()`.\n",
      "Interface loading below...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"http://127.0.0.1:7861/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f90d0522588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<Flask 'gradio.networking'>, 'http://127.0.0.1:7861/', None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 142, but you input_length is only 114. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
     ]
    }
   ],
   "source": [
    "Series(\n",
    "    translation,\n",
    "    summary,\n",
    "    title=\"Translate And Summarize Chinese Text Into English\",\n",
    "    inputs=gr.inputs.Textbox(lines=20, label=\"Paste some Chinese text here\"),\n",
    "    outputs=gr.outputs.Textbox(label=\"English Summary\"),\n",
    ").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
