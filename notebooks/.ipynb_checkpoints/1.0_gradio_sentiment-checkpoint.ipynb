{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILDING NLP WEB APPS WITH GRADIO AND HUGGING FACE TRANSFORMERS\n",
    "\n",
    "Web app design/deployment is arguably one of the biggest weaknesses among data scientists and analysts. But there's no avoiding it if you need to share an NLP/ML demo with colleagues or a client.\n",
    "\n",
    "Even a simple web app can go a long way towards demonstrating how your solution works, and what the results look like. More importantly, it allows non-technical users to test the proposed solution for themselves, and see if the product is on the right track.\n",
    "\n",
    "But a \"simple\" app can take hours to figure out if you are unfamiliar with HTML and the finicky steps involved in deploying to hosting services like Heroku or PythonAnywhere. It is doubly frustrating if you are merely in the early stages of development, when all you need is a frills-free demo.\n",
    "\n",
    "Several tools and libraries have emerged in recent years to address this need, but the most user-friendly I've used to date is [Gradio](https://gradio.app/). Its close integration with [Hugging Face](https://huggingface.co/) makes it even easier to use, if you are working on a transformers-based NLP solution.\n",
    "\n",
    "With a few lines of code, you can get a simple web app for sentiment analysis or translation up and running. You can even get away with just two lines of code, if you rely on [Hugging Face's hosted Inference API](https://huggingface.co/blog/gradio). But do note that the publicly accessible Inference API can be slow. \n",
    "\n",
    "What's even more interesting about the latest version of Gradio is that you can load multiple models in one web app, either in parallel or in series, ie, compare different translation models in one app, or combine translation and summary models in one app.\n",
    "\n",
    "Over the next few notebooks, I'll share some examples of how Gradio can be used for these standalone and \"chain-linked\" NLP apps. They'll predominantly be transformer-based examples, thought I'll have one for scikit-learn as well, using a Logistic Regression model.\n",
    "\n",
    "Let's start with a simple sentiment analysis web app using Hugging Face's pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import re\n",
    "\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DEFINE SENTIMENT ANALYSIS FUNCTION\n",
    "\n",
    "I'm using the Hugging Face pipeline to simplify the example. You can use your own finetuned transformer model if you wish.\n",
    "\n",
    "The pipeline also allows you to swap out functionalities very quickly. So if I want to use the pretrained models available in the pipeline for summarization or translation, I can just easily change a few words and I would be good to go. \n",
    "\n",
    "See [Hugging Face's documentation](https://huggingface.co/transformers/main_classes/pipelines.html) for more details on the various NLP tasks you can execute via the pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = pipeline(\"sentiment-analysis\") \n",
    "# you can swop out \"sentiment-analysis\" for other task identifiers such as \"summarization\" or \"zero-shot-classification\".\n",
    "\n",
    "# I've added optional lines for text cleaning\n",
    "# note that the sentiment-analysis pipeline returns 2 values - a label and a score\n",
    "def sentiment_analysis(text):\n",
    "    text = text.encode(\"ascii\", errors=\"ignore\").decode(\n",
    "        \"ascii\"\n",
    "    )  # remove non-ascii, Chinese characters\n",
    "    text = text.lower()  # lower case\n",
    "    text = re.sub(r\"\\n\", \" \", text)\n",
    "    text = re.sub(r\"\\n\\n\", \" \", text)\n",
    "    text = re.sub(r\"\\t\", \" \", text)\n",
    "    text = text.strip(\" \")\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # remove punctuation and special characters\n",
    "    text = re.sub(\n",
    "        \" +\", \" \", text\n",
    "    ).strip()  # get rid of multiple spaces and replace with a single\n",
    "    results = sentiment(text)\n",
    "    return results[0][\"label\"], round(results[0][\"score\"], 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DEFINE GRADIO INTERFACE\n",
    "\n",
    "The parameters for the Gradio interface are pretty intuitive and easy to use once you've tried out an example or two on your own. See the [documentation](https://gradio.app/docs) for further details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradio_ui = gr.Interface(\n",
    "    fn=sentiment_analysis,\n",
    "    title=\"Sentiment Analysis\",\n",
    "    description=\"Enter some text and see if the Distilbert model can gauge the sentiment correctly\",\n",
    "    inputs=gr.inputs.Textbox(lines=10, label=\"Paste some text here\"),\n",
    "    outputs=[\n",
    "        gr.outputs.Textbox(label=\"Sentiment Label\"),\n",
    "        gr.outputs.Textbox(label=\"Sentiment Score\"),\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 VOILA! \n",
    "\n",
    "If you've struggled to cobble together a simple web app, like I have, this is nothing short of a lifesaver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally at: http://127.0.0.1:7860/\n",
      "To create a public link, set `share=True` in `launch()`.\n",
      "Interface loading below...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"http://127.0.0.1:7860/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff36f179b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<Flask 'gradio.networking'>, 'http://127.0.0.1:7860/', None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set gradio_ui.launch(share=True) if you need to share it outside of your local machine.\n",
    "# The link works for 24 hours and as long as your notebook is running\n",
    "\n",
    "gradio_ui.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
