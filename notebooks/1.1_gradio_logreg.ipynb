{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILDING NLP WEB APPS WITH GRADIO AND LOGISTIC REGRESSION MODEL\n",
    "\n",
    "Gradio doesn't just work with Hugging Face or transformer models, of course. The library works with quite a wide range of machine learning models. See a [good list of examples here](https://gradio.app/ml_examples).\n",
    "\n",
    "Code below shows a simple example lifted off a [previous project on detecting trolls tweets by state-backed operators](https://github.com/chuachinhon/transformers_state_trolls_cch). The notebook for creating the Logistic Regression model is [here](https://github.com/chuachinhon/transformers_state_trolls_cch/blob/master/notebooks/3.0_compare_logreg_cch.ipynb).\n",
    "\n",
    "The project premise is straightforward: Use real tweets and troll tweets flagged by Twitter to train a classifier to pick out new troll tweets. In the past, deploying the trained model to a hosting provider would have involved designing some simple HTML templates, followed by writing a simple Flask app in Python. Additional time would then be needed to test if the simple app worked as intended.\n",
    "\n",
    "Gradio takes the pain out of designing the template, and allows you to demonstrate/share the results of the trained model in minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import joblib\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. LOAD MODEL, DEFINE CLEAN TEXT AND TWEET DETECT FUNCTIONS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model has been uploaded to the repo\n",
    "LR = joblib.load(\"../models/lr.pkl\")\n",
    "\n",
    "# tweak the extent of text cleaning as you wish \n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"\\n\", \" \", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)  # Change 't to 'not'\n",
    "    text = re.sub(r\"(@.*?)[\\s]\", \" \", text)  # Remove @name\n",
    "    text = re.sub(r\"$\\d+\\W+|\\b\\d+\\b|\\W+\\d+$\", \" \", text)  # remove digits\n",
    "    text = re.sub(r\"[^\\w\\s\\#]\", \"\", text)  # remove special characters except hashtags\n",
    "    text = text.strip(\" \")\n",
    "    text = re.sub(\n",
    "        \" +\", \" \", text\n",
    "    ).strip()  # get rid of multiple spaces and replace with a single\n",
    "    return text\n",
    "\n",
    "# tweet detector function for Gradio, incorporating the text cleaning function\n",
    "def tweet_detect(message):\n",
    "    data = [clean_text(message)]\n",
    "    my_prediction = LR.predict(data)\n",
    "\n",
    "    if my_prediction == 1:\n",
    "        return \"State-backed Troll Tweet\"\n",
    "    elif my_prediction == 0:\n",
    "        return \"Real Tweet\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DEFINE GRADIO INTERFACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Gradio interface\n",
    "gradio_ui = gr.Interface(\n",
    "    fn=tweet_detect,\n",
    "    title=\"Detect State Troll Tweets\",\n",
    "    description=\"Enter a tweet and see if a Logistic Regression model can identify if it's written by a state-backed operator\",\n",
    "    inputs=gr.inputs.Textbox(lines=10, label=\"Paste tweet text here\"),\n",
    "    outputs=gr.outputs.Textbox(label=\"Troll or Not\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 LAUNCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally at: http://127.0.0.1:7860/\n",
      "To create a public link, set `share=True` in `launch()`.\n",
      "Interface loading below...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"http://127.0.0.1:7860/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fd1903e4be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<Flask 'gradio.networking'>, 'http://127.0.0.1:7860/', None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gradio_ui.launch(share=True) if you need to share the link publicly\n",
    "gradio_ui.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
